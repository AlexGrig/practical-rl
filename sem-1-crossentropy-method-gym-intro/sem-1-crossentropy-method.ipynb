{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexGrig/practical-rl/blob/master/sem-1-crossentropy-method-gym-intro/sem-1-crossentropy-method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_sKHqdWrZiu"
      },
      "source": [
        "# Crossentropy method\n",
        "\n",
        "This notebook will teach you to solve reinforcement learning problems with crossentropy method. We'll follow-up by scaling everything up and using neural network policy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "metadata": {
        "id": "U-r6S9w2r4Cr",
        "outputId": "6509ccfe-e29c-4b86-a197-ae2301f334c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 155676 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.11_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.11) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.11) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym[toy_text]"
      ],
      "metadata": {
        "id": "QDqeTHbks87b",
        "outputId": "f5b0f861-31e2-4e09-b70f-0611034f86e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[toy_text] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[toy_text]) (1.21.6)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[toy_text]) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[toy_text]) (1.5.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[toy_text]) (4.12.0)\n",
            "Collecting pygame==2.1.0\n",
            "  Downloading pygame-2.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.3 MB 40 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[toy_text]) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[toy_text]) (3.8.1)\n",
            "Installing collected packages: pygame\n",
            "Successfully installed pygame-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0ax9ZmUCrZiy",
        "outputId": "caadda72-e8f4-4aee-83a7-a132d1908c54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|R: | : :\u001b[34;1mG\u001b[0m|\n",
            "| : | : : |\n",
            "|\u001b[43m \u001b[0m: : : : |\n",
            "| | : | : |\n",
            "|\u001b[35mY\u001b[0m| : |B: |\n",
            "+---------+\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "env = gym.make(\"Taxi-v3\", new_step_api=True, render_mode='ansi')\n",
        "env.reset()\n",
        "print(env.render()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FuEFdphxrZi0",
        "outputId": "1178684b-5b4c-45f4-9217-a2c9dc8d3fa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_states=500, n_actions=6\n"
          ]
        }
      ],
      "source": [
        "n_states = env.observation_space.n\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(\"n_states=%i, n_actions=%i\" % (n_states, n_actions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U-DGrb2ArZi1",
        "outputId": "f7ae4dd0-fc69-4fef-86f9-c5b885cc0b24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "4 * 4 * 25 + 4 * 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vy-IroV7rZi1",
        "outputId": "5e2a1015-b0ee-4bc9-efd9-f2c8059272a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Discrete(500), Discrete(6))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "env.observation_space, env.action_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N9xHBPrrZi2"
      },
      "source": [
        "# Create stochastic policy\n",
        "\n",
        "This time our policy should be a probability distribution.\n",
        "\n",
        "```policy[s,a] = P(take action a | in state s)```\n",
        "\n",
        "Since we still use integer state and action representations, you can use a 2-dimensional array to represent the policy.\n",
        "\n",
        "Please initialize policy __uniformly__, that is, probabililities of all actions should be equal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dlremljXrZi2"
      },
      "outputs": [],
      "source": [
        "policy = 1./n_actions * np.ones((500,6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Q0StLHGNrZi3"
      },
      "outputs": [],
      "source": [
        "assert type(policy) in (np.ndarray, np.matrix)\n",
        "assert np.allclose(policy, 1./n_actions)\n",
        "assert np.allclose(np.sum(policy, axis=1), 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYo2DAC0rZi3"
      },
      "source": [
        "# Play the game\n",
        "\n",
        "Just like before, but we also record all states and actions we took."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bWmlpu2KrZi4",
        "outputId": "2b4c35ae-b923-4af7-b79b-492dc9dbe7db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(209,\n",
              " -1,\n",
              " False,\n",
              " False,\n",
              " {'prob': 1.0, 'action_mask': array([1, 1, 1, 0, 0, 0], dtype=int8)})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "env.reset()\n",
        "tt = env.step(3)\n",
        "tt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tt)"
      ],
      "metadata": {
        "id": "rQ5Ol_1l1fQZ",
        "outputId": "485a9e07-18c4-4f51-868b-46f4e91010ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "P7M3x19frZi4",
        "outputId": "914ea565-e729-43a7-93ae-5b3c4c3b3649",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
              "       0.16666667])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "policy[6,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SLXLw0KerZi5"
      },
      "outputs": [],
      "source": [
        "def generate_session(policy, t_max=10**4, render=False, test=False):\n",
        "    \"\"\"\n",
        "    Play game until end or for t_max ticks.\n",
        "    :param policy: an array of shape [n_states, n_actions] with action probabilities\n",
        "    :returns: list of states, list of actions and sum of rewards\n",
        "    \"\"\"\n",
        "    states, actions = [], []\n",
        "    total_reward = 0.\n",
        "\n",
        "    n_states, n_actions = policy.shape\n",
        "\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "                \n",
        "        # use the probabilities you predicted to pick an action\n",
        "        if test:\n",
        "            # on the test use the best (the most likely) actions at test\n",
        "            # experiment, will it work on the train and vice versa?\n",
        "            a = np.argmax( policy[s,:] )\n",
        "            # ^-- hint: try np.argmax\n",
        "        else:\n",
        "            # sample proportionally to the probabilities,\n",
        "            # don't just take the most likely action at train\n",
        "            a = np.random.choice(np.arange(0, n_actions), p=policy[s,:] )\n",
        "            # ^-- hint: try np.random.choice\n",
        "\n",
        "        new_s, r, done, trunc, info = env.step(a)\n",
        "        \n",
        "        if render:\n",
        "            print(env.render()[0])\n",
        "\n",
        "        # record sessions like you did before\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        total_reward += r\n",
        "\n",
        "        s = new_s\n",
        "        if done:\n",
        "            break\n",
        "            \n",
        "    if render:\n",
        "        env.close()\n",
        "            \n",
        "    return states, actions, total_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6oXYi32SrZi6",
        "outputId": "f77c2473-12e9-48a4-a16b-53d5f5df2297",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "s, a, r = generate_session(policy)\n",
        "assert type(s) == type(a) == list\n",
        "assert len(s) == len(a)\n",
        "assert type(r) in [float, np.float]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ysuX17evrZi6",
        "outputId": "200065ea-9360-4acc-9082-f09aa06f7eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f881f4d9890>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# let's see the initial reward distribution\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "sample_rewards = [generate_session(policy, t_max=1000)[-1] for _ in range(200)]\n",
        "\n",
        "plt.hist(sample_rewards, bins=20)\n",
        "plt.vlines([np.percentile(sample_rewards, 50)], [0], [100], label=\"50'th percentile\", color='green')\n",
        "plt.vlines([np.percentile(sample_rewards, 90)], [0], [100], label=\"90'th percentile\", color='red')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvcGmcdbrZi7"
      },
      "source": [
        "### Crossentropy method steps (2pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZUOKhzhmrZi7"
      },
      "outputs": [],
      "source": [
        "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
        "    \"\"\"\n",
        "    Select states and actions from games that have rewards >= percentile\n",
        "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
        "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
        "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
        "\n",
        "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
        "\n",
        "    Please return elite states and actions in their original order \n",
        "    [i.e. sorted by session number and timestep within session]\n",
        "\n",
        "    If you are confused, see examples below. Please don't assume that states are integers\n",
        "    (they will become different later).\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    if percentile == 0:\n",
        "      elite_states = [vv for ll in states_batch for vv in ll] # flatten\n",
        "      elite_actions = [vv for ll in actions_batch for vv in ll] # flatten \n",
        "    else:\n",
        "      perc = np.percentile(rewards_batch, percentile)\n",
        "      inds = np.nonzero(rewards_batch >= perc)[0]\n",
        "      \n",
        "      elite_states = [vv for ii in inds for vv in states_batch[ii]]\n",
        "      elite_actions = [vv for ii in inds for vv in actions_batch[ii]]\n",
        "\n",
        "    return elite_states, elite_actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nS1BmB8XrZi7",
        "outputId": "5eff9ef8-64f2-41e4-870e-b6f7c2e555e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ok!\n"
          ]
        }
      ],
      "source": [
        "states_batch = [\n",
        "    [1, 2, 3],     # game1\n",
        "    [4, 2, 0, 2],  # game2\n",
        "    [3, 1],        # game3\n",
        "]\n",
        "\n",
        "actions_batch = [\n",
        "    [0, 2, 4],     # game1\n",
        "    [3, 2, 0, 1],  # game2\n",
        "    [3, 3],        # game3\n",
        "]\n",
        "rewards_batch = [\n",
        "    3,  # game1\n",
        "    4,  # game2\n",
        "    5,  # game3\n",
        "]\n",
        "\n",
        "test_result_0 = select_elites(\n",
        "    states_batch, actions_batch, rewards_batch, percentile=0)\n",
        "test_result_40 = select_elites(\n",
        "    states_batch, actions_batch, rewards_batch, percentile=30)\n",
        "test_result_90 = select_elites(\n",
        "    states_batch, actions_batch, rewards_batch, percentile=90)\n",
        "test_result_100 = select_elites(\n",
        "    states_batch, actions_batch, rewards_batch, percentile=100)\n",
        "\n",
        "assert np.all(test_result_0[0] == [1, 2, 3, 4, 2, 0, 2, 3, 1])  \\\n",
        "    and np.all(test_result_0[1] == [0, 2, 4, 3, 2, 0, 1, 3, 3]),\\\n",
        "    \"For percentile 0 you should return all states and actions in chronological order\"\n",
        "assert np.all(test_result_40[0] == [4, 2, 0, 2, 3, 1]) and \\\n",
        "    np.all(test_result_40[1] == [3, 2, 0, 1, 3, 3]),\\\n",
        "    \"For percentile 30 you should only select states/actions from two first\"\n",
        "assert np.all(test_result_90[0] == [3, 1]) and \\\n",
        "    np.all(test_result_90[1] == [3, 3]),\\\n",
        "    \"For percentile 90 you should only select states/actions from one game\"\n",
        "assert np.all(test_result_100[0] == [3, 1]) and\\\n",
        "    np.all(test_result_100[1] == [3, 3]),\\\n",
        "    \"Please make sure you use >=, not >. Also double-check how you compute percentile.\"\n",
        "print(\"Ok!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-q4WGYHtrZi8"
      },
      "outputs": [],
      "source": [
        "def update_policy(elite_states, elite_actions):\n",
        "    \"\"\"\n",
        "    Given old policy and a list of elite states/actions from select_elites,\n",
        "    return new updated policy where each action probability is proportional to\n",
        "\n",
        "    policy[s_i,a_i] ~ #[occurences of si and ai in elite states/actions]\n",
        "\n",
        "    Don't forget to normalize policy to get valid probabilities and handle 0/0 case.\n",
        "    In case you never visited a state, set probabilities for all actions to 1./n_actions\n",
        "\n",
        "    :param elite_states: 1D list of states from elite sessions\n",
        "    :param elite_actions: 1D list of actions from elite sessions\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #new_policy = np.ones([n_states, n_actions]) # this adds smoothing. At least one observation for each action.\n",
        "    new_policy = np.zeros([n_states, n_actions])\n",
        "    \n",
        "    np.add.at(new_policy, (elite_states, elite_actions), 1 )\n",
        "\n",
        "    # not visited states get uniform distribution\n",
        "    mask = ~np.any(new_policy, axis=1)\n",
        "    new_policy[mask] = 1\n",
        "\n",
        "    # normalize new policy\n",
        "    norm_term = new_policy.sum(axis=1)[:,np.newaxis]\n",
        "    norm_term = np.repeat(norm_term, n_actions, axis=1)\n",
        "\n",
        "    new_policy = new_policy / norm_term\n",
        "    #<Your code here: update probabilities for actions given elite states & actions >\n",
        "    # Don't forget to set 1/n_actions for all actions in unvisited states.\n",
        "\n",
        "    return new_policy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tt = np.ones([5, 2]).sum(axis=1)[:,np.newaxis]\n",
        "tt = np.repeat(tt, 3, axis=1)\n",
        "tt"
      ],
      "metadata": {
        "id": "zgDfZ-q6D8fg",
        "outputId": "57a6accb-3632-4878-ee06-3ff6e72959bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2., 2., 2.],\n",
              "       [2., 2., 2.],\n",
              "       [2., 2., 2.],\n",
              "       [2., 2., 2.],\n",
              "       [2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aa= np.array([1,2,3])[:,np.newaxis]\n",
        "np.repeat(aa, 3, axis=1)"
      ],
      "metadata": {
        "id": "ObtiSRxpDfLe",
        "outputId": "16964c91-a7c5-4ff8-91e6-3a304440a5b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1],\n",
              "       [2, 2, 2],\n",
              "       [3, 3, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "j1d987kYrZi8",
        "outputId": "e5399e90-c40e-4a3c-ddfc-81d536818f38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.         0.         0.         0.        ]\n",
            " [0.5        0.         0.         0.5        0.        ]\n",
            " [0.         0.33333333 0.66666667 0.         0.        ]\n",
            " [0.         0.         0.         0.5        0.5       ]]\n",
            "Ok!\n"
          ]
        }
      ],
      "source": [
        "elite_states = [1, 2, 3, 4, 2, 0, 2, 3, 1]\n",
        "elite_actions = [0, 2, 4, 3, 2, 0, 1, 3, 3]\n",
        "\n",
        "new_policy = update_policy(elite_states, elite_actions)\n",
        "print(new_policy[:4, :5])\n",
        "assert np.isfinite(new_policy).all(\n",
        "), \"Your new policy contains NaNs or +-inf. Make sure you don't divide by zero.\"\n",
        "assert np.all(\n",
        "    new_policy >= 0), \"Your new policy can't have negative action probabilities\"\n",
        "assert np.allclose(new_policy.sum(\n",
        "    axis=-1), 1), \"Your new policy should be a valid probability distribution over actions\"\n",
        "\n",
        "reference_answer = np.array([\n",
        "    [1.,  0.,  0.,  0.,  0.],\n",
        "    [0.5,  0.,  0.,  0.5,  0.],\n",
        "    [0.,  0.33333333,  0.66666667,  0.,  0.],\n",
        "    [0.,  0.,  0.,  0.5,  0.5]])\n",
        "assert np.allclose(new_policy[:4, :5], reference_answer)\n",
        "print(\"Ok!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stCdIBwirZi9"
      },
      "source": [
        "# Training loop\n",
        "Generate sessions, select N best and fit to those."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sVoUiGQIrZi9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
        "    \"\"\"\n",
        "    A convenience function that displays training progress. \n",
        "    No cool math here, just charts.\n",
        "    \"\"\"\n",
        "\n",
        "    mean_reward = np.mean(rewards_batch)\n",
        "    threshold = np.percentile(rewards_batch, percentile)\n",
        "    log.append([mean_reward, threshold])\n",
        "\n",
        "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
        "    plt.figure(figsize=[8, 4])\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
        "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(rewards_batch, range=reward_range)\n",
        "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
        "               [0], [100], label=\"percentile\", color='red')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    \n",
        "    clear_output(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = ['sunday', 'monday', 'tuesday', 'wednesday']\n",
        "[tt for tt in zip(*arr)]"
      ],
      "metadata": {
        "id": "YixzNfypK1B3",
        "outputId": "af24d436-7e9e-4396-b1fb-c538f9cd10b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('s', 'm', 't', 'w'),\n",
              " ('u', 'o', 'u', 'e'),\n",
              " ('n', 'n', 'e', 'd'),\n",
              " ('d', 'd', 's', 'n'),\n",
              " ('a', 'a', 'd', 'e'),\n",
              " ('y', 'y', 'a', 's')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KF7NUggfrZi-"
      },
      "outputs": [],
      "source": [
        "# reset policy just in case\n",
        "policy = np.ones([n_states, n_actions]) / n_actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EqvCNb9ErZi-",
        "outputId": "c2336363-16dd-4420-f99f-e47749359796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "n_sessions = 500  # sample this many sessions\n",
        "percentile = 50  # take this percent of session with highest rewards. \n",
        "learning_rate = 0.5  # add this thing to all counts for stability\n",
        "epochs = 20\n",
        "\n",
        "log = []\n",
        "\n",
        "for i in range(epochs):\n",
        "\n",
        "    sessions =    [generate_session(policy, t_max=10**4, render=False, test=False) for _ in range(0, n_sessions)] #[ < generate a list of n_sessions new sessions > ]\n",
        "    states_batch, actions_batch, rewards_batch = zip(*sessions)\n",
        "    \n",
        "    elite_states, elite_actions = select_elites(states_batch,\n",
        "                    actions_batch, rewards_batch, percentile) #< select elite states/actions >\n",
        "    \n",
        "    new_policy = update_policy(elite_states, elite_actions)\n",
        "    policy = (1 - learning_rate)*policy + learning_rate*new_policy\n",
        "\n",
        "    # display results on chart\n",
        "    show_progress(rewards_batch, log, percentile)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sessions[0]"
      ],
      "metadata": {
        "id": "W-Zr6SNKNOa3",
        "outputId": "45b55ad4-cdbf-4772-b93b-863f10cd74e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([31, 31, 31, 131, 231, 211, 311, 411, 419, 319, 219, 239, 259, 279, 379, 479],\n",
              " [2, 2, 0, 0, 3, 0, 0, 4, 1, 1, 2, 2, 2, 0, 0, 5],\n",
              " 5.0)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIk5LM3DrZi_",
        "outputId": "a4b770a7-d3d6-422a-9051-42f1ef675223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : :\u001b[43m \u001b[0m: : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| |\u001b[43m \u001b[0m: | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| :\u001b[43m \u001b[0m: : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : :\u001b[43m \u001b[0m: : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| |\u001b[43m \u001b[0m: | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| :\u001b[43m \u001b[0m: : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "|\u001b[43m \u001b[0m: : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "|\u001b[43m \u001b[0m: | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| :\u001b[43m \u001b[0m| : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m:\u001b[43m \u001b[0m| : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[42mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (Pickup)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "|\u001b[42m_\u001b[0m: | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "|\u001b[42m_\u001b[0m: : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| :\u001b[42m_\u001b[0m: : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "|\u001b[42m_\u001b[0m: : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| :\u001b[42m_\u001b[0m: : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : :\u001b[42m_\u001b[0m: : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : :\u001b[42m_\u001b[0m: |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : :\u001b[42m_\u001b[0m|\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | :\u001b[42m_\u001b[0m|\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m:\u001b[42m_\u001b[0m|\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35m\u001b[42mB\u001b[0m\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35m\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m\u001b[0m: |\n",
            "+---------+\n",
            "  (Dropoff)\n"
          ]
        }
      ],
      "source": [
        "generate_session(policy, render=True);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FUFbRkzrZi_"
      },
      "source": [
        "### Reflecting on results\n",
        "\n",
        "You may have noticed that the taxi problem quickly converges from <-1000 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
        "\n",
        "In case CEM failed to learn how to win from one distinct starting point, it will simply discard it because no sessions from that starting point will make it into the \"elites\".\n",
        "\n",
        "To mitigate that problem, you can either reduce the threshold for elite sessions (duct tape way) or  change the way you evaluate strategy (theoretically correct way). You can first sample an action for every possible state and then evaluate this choice of actions by running _several_ games and averaging rewards."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}