{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexGrig/practical-rl/blob/master/sem-1-crossentropy-method-gym-intro/sem-1-crossentropy-method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_sKHqdWrZiu"
      },
      "source": [
        "# Crossentropy method\n",
        "\n",
        "This notebook will teach you to solve reinforcement learning problems with crossentropy method. We'll follow-up by scaling everything up and using neural network policy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "metadata": {
        "id": "U-r6S9w2r4Cr",
        "outputId": "6509ccfe-e29c-4b86-a197-ae2301f334c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package xvfb.\n",
            "(Reading database ... 155676 files and directories currently installed.)\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.11_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.11) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.11) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Starting virtual X frame buffer: Xvfb.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym[toy_text]"
      ],
      "metadata": {
        "id": "QDqeTHbks87b",
        "outputId": "f5b0f861-31e2-4e09-b70f-0611034f86e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[toy_text] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[toy_text]) (1.21.6)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[toy_text]) (0.0.8)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[toy_text]) (1.5.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[toy_text]) (4.12.0)\n",
            "Collecting pygame==2.1.0\n",
            "  Downloading pygame-2.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 18.3 MB 40 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[toy_text]) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[toy_text]) (3.8.1)\n",
            "Installing collected packages: pygame\n",
            "Successfully installed pygame-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0ax9ZmUCrZiy",
        "outputId": "caadda72-e8f4-4aee-83a7-a132d1908c54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|R: | : :\u001b[34;1mG\u001b[0m|\n",
            "| : | : : |\n",
            "|\u001b[43m \u001b[0m: : : : |\n",
            "| | : | : |\n",
            "|\u001b[35mY\u001b[0m| : |B: |\n",
            "+---------+\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "env = gym.make(\"Taxi-v3\", new_step_api=True, render_mode='ansi')\n",
        "env.reset()\n",
        "print(env.render()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FuEFdphxrZi0",
        "outputId": "1178684b-5b4c-45f4-9217-a2c9dc8d3fa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_states=500, n_actions=6\n"
          ]
        }
      ],
      "source": [
        "n_states = env.observation_space.n\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(\"n_states=%i, n_actions=%i\" % (n_states, n_actions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "U-DGrb2ArZi1",
        "outputId": "f7ae4dd0-fc69-4fef-86f9-c5b885cc0b24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "4 * 4 * 25 + 4 * 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vy-IroV7rZi1",
        "outputId": "5e2a1015-b0ee-4bc9-efd9-f2c8059272a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Discrete(500), Discrete(6))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "env.observation_space, env.action_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N9xHBPrrZi2"
      },
      "source": [
        "# Create stochastic policy\n",
        "\n",
        "This time our policy should be a probability distribution.\n",
        "\n",
        "```policy[s,a] = P(take action a | in state s)```\n",
        "\n",
        "Since we still use integer state and action representations, you can use a 2-dimensional array to represent the policy.\n",
        "\n",
        "Please initialize policy __uniformly__, that is, probabililities of all actions should be equal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dlremljXrZi2"
      },
      "outputs": [],
      "source": [
        "policy = 1./n_actions * np.ones((500,6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Q0StLHGNrZi3"
      },
      "outputs": [],
      "source": [
        "assert type(policy) in (np.ndarray, np.matrix)\n",
        "assert np.allclose(policy, 1./n_actions)\n",
        "assert np.allclose(np.sum(policy, axis=1), 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYo2DAC0rZi3"
      },
      "source": [
        "# Play the game\n",
        "\n",
        "Just like before, but we also record all states and actions we took."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bWmlpu2KrZi4",
        "outputId": "2b4c35ae-b923-4af7-b79b-492dc9dbe7db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(209,\n",
              " -1,\n",
              " False,\n",
              " False,\n",
              " {'prob': 1.0, 'action_mask': array([1, 1, 1, 0, 0, 0], dtype=int8)})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "env.reset()\n",
        "tt = env.step(3)\n",
        "tt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tt)"
      ],
      "metadata": {
        "id": "rQ5Ol_1l1fQZ",
        "outputId": "485a9e07-18c4-4f51-868b-46f4e91010ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "P7M3x19frZi4",
        "outputId": "914ea565-e729-43a7-93ae-5b3c4c3b3649",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
              "       0.16666667])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "policy[6,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SLXLw0KerZi5"
      },
      "outputs": [],
      "source": [
        "def generate_session(policy, t_max=10**4, render=False, test=False):\n",
        "    \"\"\"\n",
        "    Play game until end or for t_max ticks.\n",
        "    :param policy: an array of shape [n_states, n_actions] with action probabilities\n",
        "    :returns: list of states, list of actions and sum of rewards\n",
        "    \"\"\"\n",
        "    states, actions = [], []\n",
        "    total_reward = 0.\n",
        "\n",
        "    n_states, n_actions = policy.shape\n",
        "\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "                \n",
        "        # use the probabilities you predicted to pick an action\n",
        "        if test:\n",
        "            # on the test use the best (the most likely) actions at test\n",
        "            # experiment, will it work on the train and vice versa?\n",
        "            a = np.argmax( policy[s,:] )\n",
        "            # ^-- hint: try np.argmax\n",
        "        else:\n",
        "            # sample proportionally to the probabilities,\n",
        "            # don't just take the most likely action at train\n",
        "            a = np.random.choice(np.arange(0, n_actions), p=policy[s,:] )\n",
        "            # ^-- hint: try np.random.choice\n",
        "\n",
        "        new_s, r, done, trunc, info = env.step(a)\n",
        "        \n",
        "        if render:\n",
        "            print(env.render()[0])\n",
        "\n",
        "        # record sessions like you did before\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        total_reward += r\n",
        "\n",
        "        s = new_s\n",
        "        if done:\n",
        "            break\n",
        "            \n",
        "    if render:\n",
        "        env.close()\n",
        "            \n",
        "    return states, actions, total_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6oXYi32SrZi6",
        "outputId": "f77c2473-12e9-48a4-a16b-53d5f5df2297",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "s, a, r = generate_session(policy)\n",
        "assert type(s) == type(a) == list\n",
        "assert len(s) == len(a)\n",
        "assert type(r) in [float, np.float]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ysuX17evrZi6",
        "outputId": "200065ea-9360-4acc-9082-f09aa06f7eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f881f4d9890>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# let's see the initial reward distribution\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "sample_rewards = [generate_session(policy, t_max=1000)[-1] for _ in range(200)]\n",
        "\n",
        "plt.hist(sample_rewards, bins=20)\n",
        "plt.vlines([np.percentile(sample_rewards, 50)], [0], [100], label=\"50'th percentile\", color='green')\n",
        "plt.vlines([np.percentile(sample_rewards, 90)], [0], [100], label=\"90'th percentile\", color='red')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvcGmcdbrZi7"
      },
      "source": [
        "### Crossentropy method steps (2pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZUOKhzhmrZi7"
      },
      "outputs": [],
      "source": [
        "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
        "    \"\"\"\n",
        "    Select states and actions from games that have rewards >= percentile\n",
        "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
        "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
        "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
        "\n",
        "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
        "\n",
        "    Please return elite states and actions in their original order \n",
        "    [i.e. sorted by session number and timestep within session]\n",
        "\n",
        "    If you are confused, see examples below. Please don't assume that states are integers\n",
        "    (they will become different later).\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    if percentile == 0:\n",
        "      elite_states = [vv for ll in states_batch for vv in ll] # flatten\n",
        "      elite_actions = [vv for ll in actions_batch for vv in ll] # flatten \n",
        "    else:\n",
        "      perc = np.percentile(rewards_batch, percentile)\n",
        "      inds = np.nonzero(rewards_batch >= perc)[0]\n",
        "      \n",
        "      elite_states = [vv for ii in inds for vv in states_batch[ii]]\n",
        "      elite_actions = [vv for ii in inds for vv in actions_batch[ii]]\n",
        "\n",
        "    return elite_states, elite_actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nS1BmB8XrZi7",
        "outputId": "5eff9ef8-64f2-41e4-870e-b6f7c2e555e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ok!\n"
          ]
        }
      ],
      "source": [
        "states_batch = [\n",
        "    [1, 2, 3],     # game1\n",
        "    [4, 2, 0, 2],  # game2\n",
        "    [3, 1],        # game3\n",
        "]\n",
        "\n",
        "actions_batch = [\n",
        "    [0, 2, 4],     # game1\n",
        "    [3, 2, 0, 1],  # game2\n",
        "    [3, 3],        # game3\n",
        "]\n",
        "rewards_batch = [\n",
        "    3,  # game1\n",
        "    4,  # game2\n",
        "    5,  # game3\n",
        "]\n",
        "\n",
        "test_result_0 = select_elites(\n",
        "    states_batch, actions_batch, rewards_batch, percentile=0)\n",
        "test_result_40 = select_elites(\n",
        "    states_batch, actions_batch, rewards_batch, percentile=30)\n",
        "test_result_90 = select_elites(\n",
        "    states_batch, actions_batch, rewards_batch, percentile=90)\n",
        "test_result_100 = select_elites(\n",
        "    states_batch, actions_batch, rewards_batch, percentile=100)\n",
        "\n",
        "assert np.all(test_result_0[0] == [1, 2, 3, 4, 2, 0, 2, 3, 1])  \\\n",
        "    and np.all(test_result_0[1] == [0, 2, 4, 3, 2, 0, 1, 3, 3]),\\\n",
        "    \"For percentile 0 you should return all states and actions in chronological order\"\n",
        "assert np.all(test_result_40[0] == [4, 2, 0, 2, 3, 1]) and \\\n",
        "    np.all(test_result_40[1] == [3, 2, 0, 1, 3, 3]),\\\n",
        "    \"For percentile 30 you should only select states/actions from two first\"\n",
        "assert np.all(test_result_90[0] == [3, 1]) and \\\n",
        "    np.all(test_result_90[1] == [3, 3]),\\\n",
        "    \"For percentile 90 you should only select states/actions from one game\"\n",
        "assert np.all(test_result_100[0] == [3, 1]) and\\\n",
        "    np.all(test_result_100[1] == [3, 3]),\\\n",
        "    \"Please make sure you use >=, not >. Also double-check how you compute percentile.\"\n",
        "print(\"Ok!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-q4WGYHtrZi8"
      },
      "outputs": [],
      "source": [
        "def update_policy(elite_states, elite_actions):\n",
        "    \"\"\"\n",
        "    Given old policy and a list of elite states/actions from select_elites,\n",
        "    return new updated policy where each action probability is proportional to\n",
        "\n",
        "    policy[s_i,a_i] ~ #[occurences of si and ai in elite states/actions]\n",
        "\n",
        "    Don't forget to normalize policy to get valid probabilities and handle 0/0 case.\n",
        "    In case you never visited a state, set probabilities for all actions to 1./n_actions\n",
        "\n",
        "    :param elite_states: 1D list of states from elite sessions\n",
        "    :param elite_actions: 1D list of actions from elite sessions\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #new_policy = np.ones([n_states, n_actions]) # this adds smoothing. At least one observation for each action.\n",
        "    new_policy = np.zeros([n_states, n_actions])\n",
        "    \n",
        "    np.add.at(new_policy, (elite_states, elite_actions), 1 )\n",
        "\n",
        "    # not visited states get uniform distribution\n",
        "    mask = ~np.any(new_policy, axis=1)\n",
        "    new_policy[mask] = 1\n",
        "\n",
        "    # normalize new policy\n",
        "    norm_term = new_policy.sum(axis=1)[:,np.newaxis]\n",
        "    norm_term = np.repeat(norm_term, n_actions, axis=1)\n",
        "\n",
        "    new_policy = new_policy / norm_term\n",
        "    #<Your code here: update probabilities for actions given elite states & actions >\n",
        "    # Don't forget to set 1/n_actions for all actions in unvisited states.\n",
        "\n",
        "    return new_policy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tt = np.ones([5, 2]).sum(axis=1)[:,np.newaxis]\n",
        "tt = np.repeat(tt, 3, axis=1)\n",
        "tt"
      ],
      "metadata": {
        "id": "zgDfZ-q6D8fg",
        "outputId": "57a6accb-3632-4878-ee06-3ff6e72959bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2., 2., 2.],\n",
              "       [2., 2., 2.],\n",
              "       [2., 2., 2.],\n",
              "       [2., 2., 2.],\n",
              "       [2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aa= np.array([1,2,3])[:,np.newaxis]\n",
        "np.repeat(aa, 3, axis=1)"
      ],
      "metadata": {
        "id": "ObtiSRxpDfLe",
        "outputId": "16964c91-a7c5-4ff8-91e6-3a304440a5b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1],\n",
              "       [2, 2, 2],\n",
              "       [3, 3, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "j1d987kYrZi8",
        "outputId": "e5399e90-c40e-4a3c-ddfc-81d536818f38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.         0.         0.         0.        ]\n",
            " [0.5        0.         0.         0.5        0.        ]\n",
            " [0.         0.33333333 0.66666667 0.         0.        ]\n",
            " [0.         0.         0.         0.5        0.5       ]]\n",
            "Ok!\n"
          ]
        }
      ],
      "source": [
        "elite_states = [1, 2, 3, 4, 2, 0, 2, 3, 1]\n",
        "elite_actions = [0, 2, 4, 3, 2, 0, 1, 3, 3]\n",
        "\n",
        "new_policy = update_policy(elite_states, elite_actions)\n",
        "print(new_policy[:4, :5])\n",
        "assert np.isfinite(new_policy).all(\n",
        "), \"Your new policy contains NaNs or +-inf. Make sure you don't divide by zero.\"\n",
        "assert np.all(\n",
        "    new_policy >= 0), \"Your new policy can't have negative action probabilities\"\n",
        "assert np.allclose(new_policy.sum(\n",
        "    axis=-1), 1), \"Your new policy should be a valid probability distribution over actions\"\n",
        "\n",
        "reference_answer = np.array([\n",
        "    [1.,  0.,  0.,  0.,  0.],\n",
        "    [0.5,  0.,  0.,  0.5,  0.],\n",
        "    [0.,  0.33333333,  0.66666667,  0.,  0.],\n",
        "    [0.,  0.,  0.,  0.5,  0.5]])\n",
        "assert np.allclose(new_policy[:4, :5], reference_answer)\n",
        "print(\"Ok!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stCdIBwirZi9"
      },
      "source": [
        "# Training loop\n",
        "Generate sessions, select N best and fit to those."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sVoUiGQIrZi9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
        "    \"\"\"\n",
        "    A convenience function that displays training progress. \n",
        "    No cool math here, just charts.\n",
        "    \"\"\"\n",
        "\n",
        "    mean_reward = np.mean(rewards_batch)\n",
        "    threshold = np.percentile(rewards_batch, percentile)\n",
        "    log.append([mean_reward, threshold])\n",
        "\n",
        "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
        "    plt.figure(figsize=[8, 4])\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
        "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(rewards_batch, range=reward_range)\n",
        "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
        "               [0], [100], label=\"percentile\", color='red')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    \n",
        "    clear_output(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = ['sunday', 'monday', 'tuesday', 'wednesday']\n",
        "[tt for tt in zip(*arr)]"
      ],
      "metadata": {
        "id": "YixzNfypK1B3",
        "outputId": "af24d436-7e9e-4396-b1fb-c538f9cd10b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('s', 'm', 't', 'w'),\n",
              " ('u', 'o', 'u', 'e'),\n",
              " ('n', 'n', 'e', 'd'),\n",
              " ('d', 'd', 's', 'n'),\n",
              " ('a', 'a', 'd', 'e'),\n",
              " ('y', 'y', 'a', 's')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "KF7NUggfrZi-"
      },
      "outputs": [],
      "source": [
        "# reset policy just in case\n",
        "policy = np.ones([n_states, n_actions]) / n_actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "EqvCNb9ErZi-",
        "outputId": "66ff578c-f6e8-424e-f7b0-c23006612180",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "n_sessions = 500  # sample this many sessions\n",
        "percentile = 50  # take this percent of session with highest rewards. \n",
        "learning_rate = 0.5  # add this thing to all counts for stability\n",
        "epochs = 20\n",
        "\n",
        "log = []\n",
        "\n",
        "for i in range(epochs):\n",
        "\n",
        "    sessions = [generate_session(policy, t_max=10**4, render=False, test=False) for _ in range(0, n_sessions)] #[ < generate a list of n_sessions new sessions > ]\n",
        "    states_batch, actions_batch, rewards_batch = zip(*sessions)\n",
        "    \n",
        "    elite_states, elite_actions = select_elites(states_batch,\n",
        "                    actions_batch, rewards_batch, percentile) #< select elite states/actions >\n",
        "    \n",
        "    new_policy = update_policy(elite_states, elite_actions)\n",
        "    policy = (1 - learning_rate)*policy + learning_rate*new_policy\n",
        "\n",
        "    # display results on chart\n",
        "    show_progress(rewards_batch, log, percentile)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sessions[0]"
      ],
      "metadata": {
        "id": "W-Zr6SNKNOa3",
        "outputId": "45b55ad4-cdbf-4772-b93b-863f10cd74e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([31, 31, 31, 131, 231, 211, 311, 411, 419, 319, 219, 239, 259, 279, 379, 479],\n",
              " [2, 2, 0, 0, 3, 0, 0, 4, 1, 1, 2, 2, 2, 0, 0, 5],\n",
              " 5.0)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIk5LM3DrZi_",
        "outputId": "a4b770a7-d3d6-422a-9051-42f1ef675223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : :\u001b[43m \u001b[0m: : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| |\u001b[43m \u001b[0m: | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| :\u001b[43m \u001b[0m: : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : :\u001b[43m \u001b[0m: : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| |\u001b[43m \u001b[0m: | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| :\u001b[43m \u001b[0m: : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "|\u001b[43m \u001b[0m: : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "|\u001b[43m \u001b[0m: | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| :\u001b[43m \u001b[0m| : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m:\u001b[43m \u001b[0m| : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[42mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (Pickup)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "|\u001b[42m_\u001b[0m: | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "|\u001b[42m_\u001b[0m: : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| :\u001b[42m_\u001b[0m: : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "|\u001b[42m_\u001b[0m: : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| :\u001b[42m_\u001b[0m: : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : :\u001b[42m_\u001b[0m: : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : :\u001b[42m_\u001b[0m: |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : :\u001b[42m_\u001b[0m|\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | :\u001b[42m_\u001b[0m|\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m:\u001b[42m_\u001b[0m|\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35m\u001b[42mB\u001b[0m\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35m\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m\u001b[0m: |\n",
            "+---------+\n",
            "  (Dropoff)\n"
          ]
        }
      ],
      "source": [
        "generate_session(policy, render=True);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FUFbRkzrZi_"
      },
      "source": [
        "### Reflecting on results\n",
        "\n",
        "You may have noticed that the taxi problem quickly converges from <-1000 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
        "\n",
        "In case CEM failed to learn how to win from one distinct starting point, it will simply discard it because no sessions from that starting point will make it into the \"elites\".\n",
        "\n",
        "To mitigate that problem, you can either reduce the threshold for elite sessions (duct tape way) or  change the way you evaluate strategy (theoretically correct way). You can first sample an action for every possible state and then evaluate this choice of actions by running _several_ games and averaging rewards."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}