{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexGrig/practical-rl/blob/master/sem-1-crossentropy-method-gym-intro/sem-1-crossentropy-method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_sKHqdWrZiu"
      },
      "source": [
        "# Crossentropy method\n",
        "\n",
        "This notebook will teach you to solve reinforcement learning problems with crossentropy method. We'll follow-up by scaling everything up and using neural network policy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "metadata": {
        "id": "U-r6S9w2r4Cr",
        "outputId": "7e18a98e-073c-4cc7-c80a-e00597f4e287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting virtual X frame buffer: Xvfb.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym[toy_text]"
      ],
      "metadata": {
        "id": "QDqeTHbks87b",
        "outputId": "bb3ba614-2862-41e8-b601-9ce01f2c7de9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[toy_text] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[toy_text]) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[toy_text]) (1.5.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[toy_text]) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[toy_text]) (4.12.0)\n",
            "Requirement already satisfied: pygame==2.1.0 in /usr/local/lib/python3.7/dist-packages (from gym[toy_text]) (2.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[toy_text]) (3.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[toy_text]) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0ax9ZmUCrZiy",
        "outputId": "c900d065-0027-4603-c152-af48919f73fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "|\u001b[43m \u001b[0m: : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "env = gym.make(\"Taxi-v3\", new_step_api=True, render_mode='ansi')\n",
        "env.reset()\n",
        "print(env.render()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FuEFdphxrZi0",
        "outputId": "b2d02c91-4612-4c52-8334-178bb0916ad5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_states=500, n_actions=6\n"
          ]
        }
      ],
      "source": [
        "n_states = env.observation_space.n\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(\"n_states=%i, n_actions=%i\" % (n_states, n_actions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "U-DGrb2ArZi1",
        "outputId": "ae5aa699-f8ea-44c1-892b-43697908ad73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "4 * 4 * 25 + 4 * 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vy-IroV7rZi1",
        "outputId": "77b0540c-a069-4f71-b884-94a175119718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Discrete(500), Discrete(6))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "env.observation_space, env.action_space"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N9xHBPrrZi2"
      },
      "source": [
        "# Create stochastic policy\n",
        "\n",
        "This time our policy should be a probability distribution.\n",
        "\n",
        "```policy[s,a] = P(take action a | in state s)```\n",
        "\n",
        "Since we still use integer state and action representations, you can use a 2-dimensional array to represent the policy.\n",
        "\n",
        "Please initialize policy __uniformly__, that is, probabililities of all actions should be equal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dlremljXrZi2"
      },
      "outputs": [],
      "source": [
        "policy = 1./n_actions * np.ones((500,6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Q0StLHGNrZi3"
      },
      "outputs": [],
      "source": [
        "assert type(policy) in (np.ndarray, np.matrix)\n",
        "assert np.allclose(policy, 1./n_actions)\n",
        "assert np.allclose(np.sum(policy, axis=1), 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYo2DAC0rZi3"
      },
      "source": [
        "# Play the game\n",
        "\n",
        "Just like before, but we also record all states and actions we took."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bWmlpu2KrZi4",
        "outputId": "93768674-e356-4a00-852a-cc7c4310a08f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(403,\n",
              " -1,\n",
              " False,\n",
              " False,\n",
              " {'prob': 1.0, 'action_mask': array([0, 1, 0, 0, 0, 0], dtype=int8)})"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "env.reset()\n",
        "tt = env.step(3)\n",
        "tt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tt)"
      ],
      "metadata": {
        "id": "rQ5Ol_1l1fQZ",
        "outputId": "d937746e-670b-4a48-a7a4-d3a3b1a2153c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "P7M3x19frZi4",
        "outputId": "3c06ccd5-b471-49ea-be16-e20563c180b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
              "       0.16666667])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "policy[6,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "SLXLw0KerZi5"
      },
      "outputs": [],
      "source": [
        "def generate_session(policy, t_max=10**4, render=False, test=False):\n",
        "    \"\"\"\n",
        "    Play game until end or for t_max ticks.\n",
        "    :param policy: an array of shape [n_states, n_actions] with action probabilities\n",
        "    :returns: list of states, list of actions and sum of rewards\n",
        "    \"\"\"\n",
        "    states, actions = [], []\n",
        "    total_reward = 0.\n",
        "\n",
        "    n_states, n_actions = policy.shape\n",
        "\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "                \n",
        "        # use the probabilities you predicted to pick an action\n",
        "        if test:\n",
        "            # on the test use the best (the most likely) actions at test\n",
        "            # experiment, will it work on the train and vice versa?\n",
        "            a = np.argmax( policy[s,:] )\n",
        "            # ^-- hint: try np.argmax\n",
        "        else:\n",
        "            # sample proportionally to the probabilities,\n",
        "            # don't just take the most likely action at train\n",
        "            a = np.random.choice(np.arange(0, n_actions), p=policy[s,:] )\n",
        "            # ^-- hint: try np.random.choice\n",
        "\n",
        "        new_s, r, done, trunc, info = env.step(a)\n",
        "        \n",
        "        if render:\n",
        "            env.render()\n",
        "\n",
        "        # record sessions like you did before\n",
        "        states.append(s)\n",
        "        actions.append(a)\n",
        "        total_reward += r\n",
        "\n",
        "        s = new_s\n",
        "        if done:\n",
        "            break\n",
        "            \n",
        "    if render:\n",
        "        env.close()\n",
        "            \n",
        "    return states, actions, total_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "6oXYi32SrZi6",
        "outputId": "6a4c7b96-8ca7-4428-c829-b6bb8ff04081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "s, a, r = generate_session(policy)\n",
        "assert type(s) == type(a) == list\n",
        "assert len(s) == len(a)\n",
        "assert type(r) in [float, np.float]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ysuX17evrZi6",
        "outputId": "59e2b2d4-06c9-4a80-876b-02606f0e2926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fec5a0976d0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# let's see the initial reward distribution\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "sample_rewards = [generate_session(policy, t_max=1000)[-1] for _ in range(200)]\n",
        "\n",
        "plt.hist(sample_rewards, bins=20)\n",
        "plt.vlines([np.percentile(sample_rewards, 50)], [0], [100], label=\"50'th percentile\", color='green')\n",
        "plt.vlines([np.percentile(sample_rewards, 90)], [0], [100], label=\"90'th percentile\", color='red')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvcGmcdbrZi7"
      },
      "source": [
        "### Crossentropy method steps (2pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ZUOKhzhmrZi7"
      },
      "outputs": [],
      "source": [
        "def select_elites(states_batch, actions_batch, rewards_batch, percentile=50):\n",
        "    \"\"\"\n",
        "    Select states and actions from games that have rewards >= percentile\n",
        "    :param states_batch: list of lists of states, states_batch[session_i][t]\n",
        "    :param actions_batch: list of lists of actions, actions_batch[session_i][t]\n",
        "    :param rewards_batch: list of rewards, rewards_batch[session_i]\n",
        "\n",
        "    :returns: elite_states,elite_actions, both 1D lists of states and respective actions from elite sessions\n",
        "\n",
        "    Please return elite states and actions in their original order \n",
        "    [i.e. sorted by session number and timestep within session]\n",
        "\n",
        "    If you are confused, see examples below. Please don't assume that states are integers\n",
        "    (they will become different later).\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    if percentile == 0:\n",
        "      elite_states = [vv for ll in states_batch for vv in ll] # flatten\n",
        "      elite_actions = [vv for ll in actions_batch for vv in ll] # flatten \n",
        "    else:\n",
        "      perc = np.percentile(rewards_batch, percentile)\n",
        "      inds = np.nonzero(rewards_batch >= perc)[0]\n",
        "      \n",
        "      elite_states = [vv for ii in inds for vv in states_batch[ii]]\n",
        "      elite_actions = [vv for ii in inds for vv in actions_batch[ii]]\n",
        "\n",
        "    return elite_states, elite_actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "nS1BmB8XrZi7",
        "outputId": "6571a36b-b788-4715-dd9a-00106ab10675",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ok!\n"
          ]
        }
      ],
      "source": [
        "states_batch = [\n",
        "    [1, 2, 3],     # game1\n",
        "    [4, 2, 0, 2],  # game2\n",
        "    [3, 1],        # game3\n",
        "]\n",
        "\n",
        "actions_batch = [\n",
        "    [0, 2, 4],     # game1\n",
        "    [3, 2, 0, 1],  # game2\n",
        "    [3, 3],        # game3\n",
        "]\n",
        "rewards_batch = [\n",
        "    3,  # game1\n",
        "    4,  # game2\n",
        "    5,  # game3\n",
        "]\n",
        "\n",
        "test_result_0 = select_elites(\n",
        "    states_batch, actions_batch, rewards_batch, percentile=0)\n",
        "test_result_40 = select_elites(\n",
        "    states_batch, actions_batch, rewards_batch, percentile=30)\n",
        "test_result_90 = select_elites(\n",
        "    states_batch, actions_batch, rewards_batch, percentile=90)\n",
        "test_result_100 = select_elites(\n",
        "    states_batch, actions_batch, rewards_batch, percentile=100)\n",
        "\n",
        "assert np.all(test_result_0[0] == [1, 2, 3, 4, 2, 0, 2, 3, 1])  \\\n",
        "    and np.all(test_result_0[1] == [0, 2, 4, 3, 2, 0, 1, 3, 3]),\\\n",
        "    \"For percentile 0 you should return all states and actions in chronological order\"\n",
        "assert np.all(test_result_40[0] == [4, 2, 0, 2, 3, 1]) and \\\n",
        "    np.all(test_result_40[1] == [3, 2, 0, 1, 3, 3]),\\\n",
        "    \"For percentile 30 you should only select states/actions from two first\"\n",
        "assert np.all(test_result_90[0] == [3, 1]) and \\\n",
        "    np.all(test_result_90[1] == [3, 3]),\\\n",
        "    \"For percentile 90 you should only select states/actions from one game\"\n",
        "assert np.all(test_result_100[0] == [3, 1]) and\\\n",
        "    np.all(test_result_100[1] == [3, 3]),\\\n",
        "    \"Please make sure you use >=, not >. Also double-check how you compute percentile.\"\n",
        "print(\"Ok!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "-q4WGYHtrZi8"
      },
      "outputs": [],
      "source": [
        "def update_policy(elite_states, elite_actions):\n",
        "    \"\"\"\n",
        "    Given old policy and a list of elite states/actions from select_elites,\n",
        "    return new updated policy where each action probability is proportional to\n",
        "\n",
        "    policy[s_i,a_i] ~ #[occurences of si and ai in elite states/actions]\n",
        "\n",
        "    Don't forget to normalize policy to get valid probabilities and handle 0/0 case.\n",
        "    In case you never visited a state, set probabilities for all actions to 1./n_actions\n",
        "\n",
        "    :param elite_states: 1D list of states from elite sessions\n",
        "    :param elite_actions: 1D list of actions from elite sessions\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    #new_policy = np.ones([n_states, n_actions]) # this adds smoothing. At least one observation for each action.\n",
        "    new_policy = np.zeros([n_states, n_actions])\n",
        "    \n",
        "    np.add.at(new_policy, (elite_states, elite_actions), 1 )\n",
        "\n",
        "    # not visited states get uniform distribution\n",
        "    mask = ~np.any(new_policy, axis=1)\n",
        "    new_policy[mask] = 1\n",
        "\n",
        "    # normalize new policy\n",
        "    norm_term = new_policy.sum(axis=1)[:,np.newaxis]\n",
        "    norm_term = np.repeat(norm_term, n_actions, axis=1)\n",
        "\n",
        "    new_policy = new_policy / norm_term\n",
        "    #<Your code here: update probabilities for actions given elite states & actions >\n",
        "    # Don't forget to set 1/n_actions for all actions in unvisited states.\n",
        "\n",
        "    return new_policy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tt = np.ones([5, 2]).sum(axis=1)[:,np.newaxis]\n",
        "tt = np.repeat(tt, 3, axis=1)\n",
        "tt"
      ],
      "metadata": {
        "id": "zgDfZ-q6D8fg",
        "outputId": "337f669d-7e6d-478d-a92d-735af1deed0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2., 2., 2.],\n",
              "       [2., 2., 2.],\n",
              "       [2., 2., 2.],\n",
              "       [2., 2., 2.],\n",
              "       [2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aa= np.array([1,2,3])[:,np.newaxis]\n",
        "np.repeat(aa, 3, axis=1)"
      ],
      "metadata": {
        "id": "ObtiSRxpDfLe",
        "outputId": "0162f8c1-526f-4726-9766-06567715e1d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1],\n",
              "       [2, 2, 2],\n",
              "       [3, 3, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "j1d987kYrZi8",
        "outputId": "d77f2ede-868d-4e31-cf36-b9339fa2e02a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.         0.         0.         0.        ]\n",
            " [0.5        0.         0.         0.5        0.        ]\n",
            " [0.         0.33333333 0.66666667 0.         0.        ]\n",
            " [0.         0.         0.         0.5        0.5       ]]\n",
            "Ok!\n"
          ]
        }
      ],
      "source": [
        "elite_states = [1, 2, 3, 4, 2, 0, 2, 3, 1]\n",
        "elite_actions = [0, 2, 4, 3, 2, 0, 1, 3, 3]\n",
        "\n",
        "new_policy = update_policy(elite_states, elite_actions)\n",
        "print(new_policy[:4, :5])\n",
        "assert np.isfinite(new_policy).all(\n",
        "), \"Your new policy contains NaNs or +-inf. Make sure you don't divide by zero.\"\n",
        "assert np.all(\n",
        "    new_policy >= 0), \"Your new policy can't have negative action probabilities\"\n",
        "assert np.allclose(new_policy.sum(\n",
        "    axis=-1), 1), \"Your new policy should be a valid probability distribution over actions\"\n",
        "\n",
        "reference_answer = np.array([\n",
        "    [1.,  0.,  0.,  0.,  0.],\n",
        "    [0.5,  0.,  0.,  0.5,  0.],\n",
        "    [0.,  0.33333333,  0.66666667,  0.,  0.],\n",
        "    [0.,  0.,  0.,  0.5,  0.5]])\n",
        "assert np.allclose(new_policy[:4, :5], reference_answer)\n",
        "print(\"Ok!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stCdIBwirZi9"
      },
      "source": [
        "# Training loop\n",
        "Generate sessions, select N best and fit to those."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "sVoUiGQIrZi9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "def show_progress(rewards_batch, log, percentile, reward_range=[-990, +10]):\n",
        "    \"\"\"\n",
        "    A convenience function that displays training progress. \n",
        "    No cool math here, just charts.\n",
        "    \"\"\"\n",
        "\n",
        "    mean_reward = np.mean(rewards_batch)\n",
        "    threshold = np.percentile(rewards_batch, percentile)\n",
        "    log.append([mean_reward, threshold])\n",
        "\n",
        "    print(\"mean reward = %.3f, threshold=%.3f\" % (mean_reward, threshold))\n",
        "    plt.figure(figsize=[8, 4])\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(list(zip(*log))[0], label='Mean rewards')\n",
        "    plt.plot(list(zip(*log))[1], label='Reward thresholds')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(rewards_batch, range=reward_range)\n",
        "    plt.vlines([np.percentile(rewards_batch, percentile)],\n",
        "               [0], [100], label=\"percentile\", color='red')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    \n",
        "    clear_output(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = ['sunday', 'monday', 'tuesday', 'wednesday']\n",
        "[tt for tt in zip(*arr)]"
      ],
      "metadata": {
        "id": "YixzNfypK1B3",
        "outputId": "15420836-c077-4f3b-9731-564ed4ddfa80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('s', 'm', 't', 'w'),\n",
              " ('u', 'o', 'u', 'e'),\n",
              " ('n', 'n', 'e', 'd'),\n",
              " ('d', 'd', 's', 'n'),\n",
              " ('a', 'a', 'd', 'e'),\n",
              " ('y', 'y', 'a', 's')]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KF7NUggfrZi-"
      },
      "outputs": [],
      "source": [
        "# reset policy just in case\n",
        "policy = np.ones([n_states, n_actions]) / n_actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "EqvCNb9ErZi-",
        "outputId": "6cfd3aff-d817-4558-b4e8-9d858cc5b326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "n_sessions = 500  # sample this many sessions\n",
        "percentile = 50  # take this percent of session with highest rewards\n",
        "learning_rate = 0.5  # add this thing to all counts for stability\n",
        "epochs = 20\n",
        "\n",
        "log = []\n",
        "\n",
        "for i in range(epochs):\n",
        "\n",
        "    sessions =    [generate_session(policy, t_max=10**4, render=False, test=False) for _ in range(0, n_sessions)] #[ < generate a list of n_sessions new sessions > ]\n",
        "    states_batch, actions_batch, rewards_batch = zip(*sessions)\n",
        "    \n",
        "    elite_states, elite_actions = select_elites(states_batch,\n",
        "                    actions_batch, rewards_batch, percentile) #< select elite states/actions >\n",
        "    \n",
        "    new_policy = update_policy(elite_states, elite_actions)\n",
        "    policy = (1 - learning_rate)*policy + learning_rate*new_policy\n",
        "\n",
        "    # display results on chart\n",
        "    show_progress(rewards_batch, log, percentile)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sessions[0]"
      ],
      "metadata": {
        "id": "W-Zr6SNKNOa3",
        "outputId": "45b55ad4-cdbf-4772-b93b-863f10cd74e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([31, 31, 31, 131, 231, 211, 311, 411, 419, 319, 219, 239, 259, 279, 379, 479],\n",
              " [2, 2, 0, 0, 3, 0, 0, 4, 1, 1, 2, 2, 2, 0, 0, 5],\n",
              " 5.0)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIk5LM3DrZi_",
        "outputId": "a4b770a7-d3d6-422a-9051-42f1ef675223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : :\u001b[43m \u001b[0m: : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| |\u001b[43m \u001b[0m: | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| :\u001b[43m \u001b[0m: : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : :\u001b[43m \u001b[0m: : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | :\u001b[43m \u001b[0m| : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| |\u001b[43m \u001b[0m: | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| :\u001b[43m \u001b[0m: : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "|\u001b[43m \u001b[0m: : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "|\u001b[43m \u001b[0m: | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| :\u001b[43m \u001b[0m| : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m:\u001b[43m \u001b[0m| : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[42mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (Pickup)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "|\u001b[42m_\u001b[0m: | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "|\u001b[42m_\u001b[0m: : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| :\u001b[42m_\u001b[0m: : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "|\u001b[42m_\u001b[0m: : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| :\u001b[42m_\u001b[0m: : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : :\u001b[42m_\u001b[0m: : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : :\u001b[42m_\u001b[0m: |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : :\u001b[42m_\u001b[0m|\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | :\u001b[42m_\u001b[0m|\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m:\u001b[42m_\u001b[0m|\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35m\u001b[42mB\u001b[0m\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[35m\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m\u001b[0m: |\n",
            "+---------+\n",
            "  (Dropoff)\n"
          ]
        }
      ],
      "source": [
        "generate_session(policy, render=True);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FUFbRkzrZi_"
      },
      "source": [
        "### Reflecting on results\n",
        "\n",
        "You may have noticed that the taxi problem quickly converges from <-1000 to a near-optimal score and then descends back into -50/-100. This is in part because the environment has some innate randomness. Namely, the starting points of passenger/driver change from episode to episode.\n",
        "\n",
        "In case CEM failed to learn how to win from one distinct starting point, it will simply discard it because no sessions from that starting point will make it into the \"elites\".\n",
        "\n",
        "To mitigate that problem, you can either reduce the threshold for elite sessions (duct tape way) or  change the way you evaluate strategy (theoretically correct way). You can first sample an action for every possible state and then evaluate this choice of actions by running _several_ games and averaging rewards."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}